{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0986de99",
   "metadata": {},
   "source": [
    "# IMPORT DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4cafff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ffb4cede",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Aakash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aakash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "da43ac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291de52a",
   "metadata": {},
   "source": [
    "# LOAD INPUT FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c6d5fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign0001</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign0002</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign0003</td>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign0004</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign0005</td>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            URL_ID                                                URL\n",
       "0  blackassign0001  https://insights.blackcoffer.com/rising-it-cit...\n",
       "1  blackassign0002  https://insights.blackcoffer.com/rising-it-cit...\n",
       "2  blackassign0003  https://insights.blackcoffer.com/internet-dema...\n",
       "3  blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...\n",
       "4  blackassign0005  https://insights.blackcoffer.com/ott-platform-..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Input.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6360c567",
   "metadata": {},
   "source": [
    "### We drop URL_ID and we have to loop each url and extract data using BS lets do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e4a4f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('URL_ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98c2335d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL\n",
       "0  https://insights.blackcoffer.com/rising-it-cit...\n",
       "1  https://insights.blackcoffer.com/rising-it-cit...\n",
       "2  https://insights.blackcoffer.com/internet-dema...\n",
       "3  https://insights.blackcoffer.com/rise-of-cyber...\n",
       "4  https://insights.blackcoffer.com/ott-platform-..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba7dab2",
   "metadata": {},
   "source": [
    "# EXTRACT DATA FROM EACH URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b22cba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the URL ID\n",
    "url_id = 1\n",
    "\n",
    "# Assuming df is your DataFrame with URLs\n",
    "for i in range(len(df)):\n",
    "    j = df.iloc[i].values\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36'}\n",
    "    page = requests.get(j[0], headers=headers)\n",
    "\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    # Find the content\n",
    "    content = soup.findAll(attrs={'class': 'td-post-content'})\n",
    "    if content:\n",
    "        content_text = content[0].text.replace('\\xa0', \"  \").replace('\\n', \"  \")\n",
    "    else:\n",
    "        content_text = \"Content not found\"\n",
    "\n",
    "    # Find the title\n",
    "    title = soup.findAll(attrs={'class': 'entry-title'})\n",
    "    if title:\n",
    "        # Ensure there are enough elements in the title list to access the 17th element (index 16)\n",
    "        if len(title) > 16:\n",
    "            title_text = title[16].text.replace('\\n', \"  \").replace('/', \"\")\n",
    "        else:\n",
    "            title_text = \"Title not found\"\n",
    "    else:\n",
    "        title_text = \"Title not found\"\n",
    "\n",
    "    # Combine title and content\n",
    "    text = title_text + '.' + content_text\n",
    "\n",
    "    # Save text to a pandas Series\n",
    "    df1 = pd.Series([text])\n",
    "\n",
    "    # Save text to a file\n",
    "#     file_name = f\"{url_id}.txt\"\n",
    "#     with open(file_name, 'w', encoding='utf-8') as f:\n",
    "#         f.write(text)\n",
    "\n",
    "    # Increment URL ID\n",
    "    url_id += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3d6386bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "15efca86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI Bot Audio to audio.    As business close to help prevent transmission of COVID-19, financial concerns and job losses are one of the first human impacts of the virus;  Not knowing how this pandemic will play out also affects our economic, physical and mental well-being;Despite this fear, businesses and communities in many regions have shown a more altruistic response in the face of crisis – actions which could help countries preparing for COVID-19.  COVID-19 is in decline in China. There are now more new cases every day in Europe than there were in China at the epidemic’s peak and Italy has surpassed it as the country with the most deaths from the virus It took 67 days to reach the first 100,000 confirmed cases worldwide, 11 days for this to increase to 200,000and just four to reach 300,000 confirmed cases – a figure now exceeded.  The Human Consequences  In recent weeks, we have seen the significant economic impact of the coronavirus on financial markets and vulnerable industries such as manufacturing, tourism, hospitality and travel.  Travel and tourism account for 10% of the global GDP and 50 million jobs are at risk worldwide.  Global tourism, travel and hospitality companies closing down affects SMEs globally. This, in turn, affects many people, typically the least well-paid and those self-employed or working in informal environments in the gig economy or in part-time work with zero-hours contracts. Some governments have announced economic measures to safeguard jobs, guarantee wages and support the self-employed, but there is a lack of clarity in many countries about how these measures will be implemented and how people will manage a loss of income in the short-term.  Behind these statistics lie the human costs of the pandemic, from the deaths of friends and family to the physical effects of infection and the mental trauma and fear faced by almost everyone. Not knowing how this pandemic will play out affects our economic, physical and mental well-being against a backdrop of a world that, for many, is increasingly anxious, unhappy and lonely.  Fear of the unknown can often lead to feelings of panic, for example when people feel they are being denied life-saving protection or treatment or that they may run out of necessities, which can lead to panic buying.Psychological stress is often related to a sense of a lack of control in the face of uncertainty.  In all cases, lack of information or the wrong information, either provided inadvertently or maliciously, can amplify the effects. There is a huge amount of misleading information circulating online about COVID-19, from fake medical information to speculation about government responses. People are susceptible to social media posts from an apparently trustworthy source, often referred to as an “Uncle with a Masters”-post, possibly amplified and spread by “copypasta” posts, which share information by copying and pasting and make each new post look like an original source, as opposed to posts that are “liked” or “shared” or “retweeted”.  Sadly, criminals and hackers are also exploiting this situation and there has been a significant rise in Coronavirus-themed malicious websites, with more than 16,000 new coronavirus-related domains registered since January 2020. Hackers are selling malware and hacking tools through COVID-19 discount codes on the darknet,many of which are aimed at accessing corporate data from home-workers’ laptops, which may not be as secure as outside an office environment.  Social distancing and lockdowns have also prompted altruistic behaviors, in part because of the sense that “we’re all in this together”. Many people report being bored or concerned about putting on weight;  others have discovered a slower pace of life and by not going out and socializing have found more time for family, others, and even their pets.  The downside of self-isolation or social lockdown are symptoms of traumatic stress, confusion and anger, all of which are exacerbated by fear of infection, having limited access to supplies of necessities, inadequate information or the experience of economic loss or stigma. This stress and anxiety can lead to increased alcohol consumption, as well as an increase in domestic and family violence.In Jingzhou, a town near Wuhan in Hubei province, reports of domestic violence during the lockdown in February 2020 were more than triple the number reported in February 2019.  Essential Actions From The Business Community  Health measures must be the first priority for governments, business and society. It is important for businesses to show solidarity and work together to protect staff, local communities and customers, as well as keeping supply chains, manufacturing and logistics working.According to research, “my employer” is more trusted than the government or media. Daily updates on a company website with input from scientists and experts are recommended to counter politicized messages in the media and from governments. This is particularly true for large companies that have the capacity to do this.  Messages about what businesses are doing for their employees and in their communities is also important. Some companies are helping schoolchildren from vulnerable families who can no longer get a school meal; others are providing public health messages about effective handwashing. Even CEOs can show they are working from home and self-isolating, while still being effective in their leadership.  Following WHO advice, there is a need for the business community to move from general support to specific actions and focus on countries’ access to critical supplies, including a “Community Package of Critical Items” (a list of 46 items that all countries need). Of these items, 20 are either not available locally or available stocks are too limited. These missing items fall into four categories:  Hygiene: Chlorine, HTH 70%, alcohol based hand rub, liquid soap;Diagnostics: lab screening tests, lab confirmation tests, enzymes, RNA extraction kits;PPE: gowns, scrubs, aprons, sterile gloves, protective goggles, face shields, masks (N95 or FFP2);Case management equipment: oxygen concentrators, oxygen delivery systems, mechanical ventilators.  The call for action is for more money, to work with manufacturers to create capacity and to organize purchasing so there is guaranteed access, especially for poorer countries with less resilient public health systems. The concept is to create a global security stockpile of supplies and equipment, an effort that needs:  Emergency financingAccess to and increases in manufacturing capacityAccess to national and supplier stockpilesWarehouses and distribution capacity  Blackcoffer Insights 17:-Jatin Tiwari,Gurukul Kangri Deemed University, Haridwar  '"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f55faf",
   "metadata": {},
   "source": [
    "# CONVERT TEXT TO SENTENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0e1beab9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 abc\n",
      "0                             AI Bot Audio to audio.\n",
      "0     As business close to help prevent transmiss...\n",
      "0                   COVID-19 is in decline in China.\n",
      "0  There are now more new cases every day in Euro...\n",
      "0   The Human Consequences  In recent weeks, we h...\n",
      "0   Travel and tourism account for 10% of the glo...\n",
      "0   Global tourism, travel and hospitality compan...\n",
      "0  This, in turn, affects many people, typically ...\n",
      "0  Some governments have announced economic measu...\n",
      "0   Behind these statistics lie the human costs o...\n",
      "0  Not knowing how this pandemic will play out af...\n",
      "0   Fear of the unknown can often lead to feeling...\n",
      "0   In all cases, lack of information or the wron...\n",
      "0  There is a huge amount of misleading informati...\n",
      "0  People are susceptible to social media posts f...\n",
      "0   Sadly, criminals and hackers are also exploit...\n",
      "0  Hackers are selling malware and hacking tools ...\n",
      "0   Social distancing and lockdowns have also pro...\n",
      "0  Many people report being bored or concerned ab...\n",
      "0   The downside of self-isolation or social lock...\n",
      "0  This stress and anxiety can lead to increased ...\n",
      "0   Essential Actions From The Business Community...\n",
      "0  It is important for businesses to show solidar...\n",
      "0  Daily updates on a company website with input ...\n",
      "0  This is particularly true for large companies ...\n",
      "0   Messages about what businesses are doing for ...\n",
      "0  Some companies are helping schoolchildren from...\n",
      "0  Even CEOs can show they are working from home ...\n",
      "0   Following WHO advice, there is a need for the...\n",
      "0  Of these items, 20 are either not available lo...\n",
      "0  These missing items fall into four categories:...\n",
      "0   The call for action is for more money, to wor...\n",
      "0  The concept is to create a global security sto...\n"
     ]
    }
   ],
   "source": [
    "# Assuming `text` is already a list or array of strings, convert it to a pandas Series\n",
    "text = pd.Series(text)\n",
    "\n",
    "# Splitting text on '. ' (dot followed by a space)\n",
    "a = text.str.split(r'(?<=[.])\\s', expand=False)  # splitting on '. ' using regex to keep the period with the sentence\n",
    "\n",
    "# Explode to convert list elements to rows\n",
    "b = a.explode()\n",
    "\n",
    "# Create DataFrame\n",
    "b = pd.DataFrame(b, columns=['abc'])\n",
    "\n",
    "print(b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c2204e",
   "metadata": {},
   "source": [
    "### removing . char from each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b6f61f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abcd(x):    \n",
    "    nopunc =[char for char in x if char != '.']\n",
    "    return ''.join(nopunc)\n",
    "b['abc']=b['abc'].apply(abcd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc978434",
   "metadata": {},
   "source": [
    "### replacing emty space with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d24ce366",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=b.replace('',np.nan,regex=True)\n",
    "c=c.mask(c==\" \")\n",
    "c=c.dropna()\n",
    "c.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f0100e31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AI Bot Audio to audio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As business close to help prevent transmiss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COVID-19 is in decline in China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>There are now more new cases every day in Euro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Human Consequences  In recent weeks, we h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Travel and tourism account for 10% of the glo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Global tourism, travel and hospitality compan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This, in turn, affects many people, typically ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Some governments have announced economic measu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Behind these statistics lie the human costs o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Not knowing how this pandemic will play out af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Fear of the unknown can often lead to feeling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>In all cases, lack of information or the wron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>There is a huge amount of misleading informati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>People are susceptible to social media posts f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sadly, criminals and hackers are also exploit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Hackers are selling malware and hacking tools ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Social distancing and lockdowns have also pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Many people report being bored or concerned ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The downside of self-isolation or social lock...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>This stress and anxiety can lead to increased ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Essential Actions From The Business Community...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>It is important for businesses to show solidar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Daily updates on a company website with input ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>This is particularly true for large companies ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Messages about what businesses are doing for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Some companies are helping schoolchildren from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Even CEOs can show they are working from home ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Following WHO advice, there is a need for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Of these items, 20 are either not available lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>These missing items fall into four categories:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>The call for action is for more money, to wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>The concept is to create a global security sto...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  abc\n",
       "0                               AI Bot Audio to audio\n",
       "1      As business close to help prevent transmiss...\n",
       "2                     COVID-19 is in decline in China\n",
       "3   There are now more new cases every day in Euro...\n",
       "4    The Human Consequences  In recent weeks, we h...\n",
       "5    Travel and tourism account for 10% of the glo...\n",
       "6    Global tourism, travel and hospitality compan...\n",
       "7   This, in turn, affects many people, typically ...\n",
       "8   Some governments have announced economic measu...\n",
       "9    Behind these statistics lie the human costs o...\n",
       "10  Not knowing how this pandemic will play out af...\n",
       "11   Fear of the unknown can often lead to feeling...\n",
       "12   In all cases, lack of information or the wron...\n",
       "13  There is a huge amount of misleading informati...\n",
       "14  People are susceptible to social media posts f...\n",
       "15   Sadly, criminals and hackers are also exploit...\n",
       "16  Hackers are selling malware and hacking tools ...\n",
       "17   Social distancing and lockdowns have also pro...\n",
       "18  Many people report being bored or concerned ab...\n",
       "19   The downside of self-isolation or social lock...\n",
       "20  This stress and anxiety can lead to increased ...\n",
       "21   Essential Actions From The Business Community...\n",
       "22  It is important for businesses to show solidar...\n",
       "23  Daily updates on a company website with input ...\n",
       "24  This is particularly true for large companies ...\n",
       "25   Messages about what businesses are doing for ...\n",
       "26  Some companies are helping schoolchildren from...\n",
       "27  Even CEOs can show they are working from home ...\n",
       "28   Following WHO advice, there is a need for the...\n",
       "29  Of these items, 20 are either not available lo...\n",
       "30  These missing items fall into four categories:...\n",
       "31   The call for action is for more money, to wor...\n",
       "32  The concept is to create a global security sto..."
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf50d35",
   "metadata": {},
   "source": [
    "# APPLAY STOPWORDS AND NLTK LIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "db7e5dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "punc=[punc for punc in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5b7f75e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_stopwords(filepath):\n",
    "    with open(filepath, 'r', encoding=\"ISO-8859-1\") as file:\n",
    "        stopwords = file.read().splitlines()\n",
    "    return pd.DataFrame(stopwords, columns=['stopword'])\n",
    "\n",
    "StopWords_Auditor = read_stopwords(\"./StopWords-20240612T123345Z-001/StopWords/StopWords_Auditor.txt\")\n",
    "StopWords_Currencies = read_stopwords(\"./StopWords-20240612T123345Z-001/StopWords/StopWords_Currencies.txt\")\n",
    "StopWords_DatesandNumbers = read_stopwords(\"./StopWords-20240612T123345Z-001/StopWords/StopWords_DatesandNumbers.txt\")\n",
    "StopWords_Generic = read_stopwords(\"./StopWords-20240612T123345Z-001/StopWords/StopWords_Generic.txt\")\n",
    "StopWords_GenericLong = read_stopwords(\"./StopWords-20240612T123345Z-001/StopWords/StopWords_GenericLong.txt\")\n",
    "StopWords_Geographic = read_stopwords(\"./StopWords-20240612T123345Z-001/StopWords/StopWords_Geographic.txt\")\n",
    "StopWords_Names = read_stopwords(\"./StopWords-20240612T123345Z-001/StopWords/StopWords_Names.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "27f1ca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(text):\n",
    "    nopunc =[char for char in text if char not in punc or char not in [':',',','(',')','’','?']]\n",
    "    nopunc=''.join(nopunc)\n",
    "    txt=' '.join([word for word in nopunc.split() if word.lower() not in StopWords_Auditor])\n",
    "    txt1=' '.join([word for word in txt.split() if word.lower() not in StopWords_Currencies])\n",
    "    txt2=' '.join([word for word in txt1.split() if word.lower() not in StopWords_DatesandNumbers])\n",
    "    txt3=' '.join([word for word in txt2.split() if word.lower() not in StopWords_Generic])\n",
    "    txt4=' '.join([word for word in txt3.split() if word.lower() not in StopWords_GenericLong])\n",
    "    txt5=' '.join([word for word in txt4.split() if word.lower() not in StopWords_Geographic])\n",
    "    return ' '.join([word for word in txt5.split() if word.lower() not in StopWords_Names])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1db57bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "c['abc']=c['abc'].apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f7b852a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AI Bot Audio to audio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As business close to help prevent transmission...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COVID-19 is in decline in China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>There are now more new cases every day in Euro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Human Consequences In recent weeks we have...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 abc\n",
       "0                              AI Bot Audio to audio\n",
       "1  As business close to help prevent transmission...\n",
       "2                    COVID-19 is in decline in China\n",
       "3  There are now more new cases every day in Euro...\n",
       "4  The Human Consequences In recent weeks we have..."
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41393c46",
   "metadata": {},
   "source": [
    "# IMPORTING MASTER DIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "56851bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_words(filepath, encoding=None):\n",
    "    with open(filepath, 'r', encoding=encoding) as file:\n",
    "        words = file.read().splitlines()\n",
    "    return pd.DataFrame(words, columns=['word'])\n",
    "\n",
    "positive = read_words(\"./MasterDictionary-20240612T123345Z-001/MasterDictionary/positive-words.txt\")\n",
    "negative = read_words(\"./MasterDictionary-20240612T123345Z-001/MasterDictionary/negative-words.txt\", encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ba41eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive.columns=['abc']\n",
    "negative.columns=['abc']\n",
    "positive['abc']=positive['abc'].astype(str)\n",
    "negative['abc']=negative['abc'].astype(str)\n",
    "     \n",
    "\n",
    "#positive and negative dictionary without stopwords\n",
    "positive['abc']=positive['abc'].apply(text_process)\n",
    "negative['abc']=negative['abc'].apply(text_process)\n",
    "     \n",
    "\n",
    "#positive list\n",
    "length=positive.shape[0]\n",
    "post=[]\n",
    "for i in range(0,length):\n",
    "   nopunc =[char for char in positive.iloc[i] if char not in string.punctuation or char != '+']\n",
    "   nopunc=''.join(nopunc)\n",
    "\n",
    "   post.append(nopunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "df1db0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "length=negative.shape[0]\n",
    "neg=[]\n",
    "for i in range(0,length):\n",
    "  nopunc =[char for char in negative.iloc[i] if char not in string.punctuation or char != '+']\n",
    "  nopunc=''.join(nopunc)\n",
    "  neg.append(nopunc)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade4e892",
   "metadata": {},
   "source": [
    "# TOKENIZE WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ea68667f",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_list=[]\n",
    "length=c.shape[0]\n",
    "for i in range(0,length):\n",
    "  txt=' '.join([word for word in c.iloc[i]])\n",
    "  txt_list.append(txt)\n",
    "     \n",
    "\n",
    "#tokenization of text\n",
    "tokenize_text=[]\n",
    "for i in txt_list:\n",
    "  \n",
    "  tokenize_text+=(word_tokenize(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6cd36b52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AI', 'Bot', 'Audio', 'to', 'audio', 'As', 'business', 'close', 'to', 'help', 'prevent', 'transmission', 'of', 'COVID-19', 'financial', 'concerns', 'and', 'job', 'losses', 'are', 'one', 'of', 'the', 'first', 'human', 'impacts', 'of', 'the', 'virus', ';', 'Not', 'knowing', 'how', 'this', 'pandemic', 'will', 'play', 'out', 'also', 'affects', 'our', 'economic', 'physical', 'and', 'mental', 'well-being', ';', 'Despite', 'this', 'fear', 'businesses', 'and', 'communities', 'in', 'many', 'regions', 'have', 'shown', 'a', 'more', 'altruistic', 'response', 'in', 'the', 'face', 'of', 'crisis', '–', 'actions', 'which', 'could', 'help', 'countries', 'preparing', 'for', 'COVID-19', 'COVID-19', 'is', 'in', 'decline', 'in', 'China', 'There', 'are', 'now', 'more', 'new', 'cases', 'every', 'day', 'in', 'Europe', 'than', 'there', 'were', 'in', 'China', 'at', 'the', 'epidemic', '’', 's', 'peak', 'and', 'Italy', 'has', 'surpassed', 'it', 'as', 'the', 'country', 'with', 'the', 'most', 'deaths', 'from', 'the', 'virus', 'It', 'took', '67', 'days', 'to', 'reach', 'the', 'first', '100000', 'confirmed', 'cases', 'worldwide', '11', 'days', 'for', 'this', 'to', 'increase', 'to', '200000and', 'just', 'four', 'to', 'reach', '300000', 'confirmed', 'cases', '–', 'a', 'figure', 'now', 'exceeded', 'The', 'Human', 'Consequences', 'In', 'recent', 'weeks', 'we', 'have', 'seen', 'the', 'significant', 'economic', 'impact', 'of', 'the', 'coronavirus', 'on', 'financial', 'markets', 'and', 'vulnerable', 'industries', 'such', 'as', 'manufacturing', 'tourism', 'hospitality', 'and', 'travel', 'Travel', 'and', 'tourism', 'account', 'for', '10', '%', 'of', 'the', 'global', 'GDP', 'and', '50', 'million', 'jobs', 'are', 'at', 'risk', 'worldwide', 'Global', 'tourism', 'travel', 'and', 'hospitality', 'companies', 'closing', 'down', 'affects', 'SMEs', 'globally', 'This', 'in', 'turn', 'affects', 'many', 'people', 'typically', 'the', 'least', 'well-paid', 'and', 'those', 'self-employed', 'or', 'working', 'in', 'informal', 'environments', 'in', 'the', 'gig', 'economy', 'or', 'in', 'part-time', 'work', 'with', 'zero-hours', 'contracts', 'Some', 'governments', 'have', 'announced', 'economic', 'measures', 'to', 'safeguard', 'jobs', 'guarantee', 'wages', 'and', 'support', 'the', 'self-employed', 'but', 'there', 'is', 'a', 'lack', 'of', 'clarity', 'in', 'many', 'countries', 'about', 'how', 'these', 'measures', 'will', 'be', 'implemented', 'and', 'how', 'people', 'will', 'manage', 'a', 'loss', 'of', 'income', 'in', 'the', 'short-term', 'Behind', 'these', 'statistics', 'lie', 'the', 'human', 'costs', 'of', 'the', 'pandemic', 'from', 'the', 'deaths', 'of', 'friends', 'and', 'family', 'to', 'the', 'physical', 'effects', 'of', 'infection', 'and', 'the', 'mental', 'trauma', 'and', 'fear', 'faced', 'by', 'almost', 'everyone', 'Not', 'knowing', 'how', 'this', 'pandemic', 'will', 'play', 'out', 'affects', 'our', 'economic', 'physical', 'and', 'mental', 'well-being', 'against', 'a', 'backdrop', 'of', 'a', 'world', 'that', 'for', 'many', 'is', 'increasingly', 'anxious', 'unhappy', 'and', 'lonely', 'Fear', 'of', 'the', 'unknown', 'can', 'often', 'lead', 'to', 'feelings', 'of', 'panic', 'for', 'example', 'when', 'people', 'feel', 'they', 'are', 'being', 'denied', 'life-saving', 'protection', 'or', 'treatment', 'or', 'that', 'they', 'may', 'run', 'out', 'of', 'necessities', 'which', 'can', 'lead', 'to', 'panic', 'buyingPsychological', 'stress', 'is', 'often', 'related', 'to', 'a', 'sense', 'of', 'a', 'lack', 'of', 'control', 'in', 'the', 'face', 'of', 'uncertainty', 'In', 'all', 'cases', 'lack', 'of', 'information', 'or', 'the', 'wrong', 'information', 'either', 'provided', 'inadvertently', 'or', 'maliciously', 'can', 'amplify', 'the', 'effects', 'There', 'is', 'a', 'huge', 'amount', 'of', 'misleading', 'information', 'circulating', 'online', 'about', 'COVID-19', 'from', 'fake', 'medical', 'information', 'to', 'speculation', 'about', 'government', 'responses', 'People', 'are', 'susceptible', 'to', 'social', 'media', 'posts', 'from', 'an', 'apparently', 'trustworthy', 'source', 'often', 'referred', 'to', 'as', 'an', '“', 'Uncle', 'with', 'a', 'Masters', '”', '-post', 'possibly', 'amplified', 'and', 'spread', 'by', '“', 'copypasta', '”', 'posts', 'which', 'share', 'information', 'by', 'copying', 'and', 'pasting', 'and', 'make', 'each', 'new', 'post', 'look', 'like', 'an', 'original', 'source', 'as', 'opposed', 'to', 'posts', 'that', 'are', '“', 'liked', '”', 'or', '“', 'shared', '”', 'or', '“', 'retweeted', '”', 'Sadly', 'criminals', 'and', 'hackers', 'are', 'also', 'exploiting', 'this', 'situation', 'and', 'there', 'has', 'been', 'a', 'significant', 'rise', 'in', 'Coronavirus-themed', 'malicious', 'websites', 'with', 'more', 'than', '16000', 'new', 'coronavirus-related', 'domains', 'registered', 'since', 'January', '2020', 'Hackers', 'are', 'selling', 'malware', 'and', 'hacking', 'tools', 'through', 'COVID-19', 'discount', 'codes', 'on', 'the', 'darknetmany', 'of', 'which', 'are', 'aimed', 'at', 'accessing', 'corporate', 'data', 'from', 'home-workers', '’', 'laptops', 'which', 'may', 'not', 'be', 'as', 'secure', 'as', 'outside', 'an', 'office', 'environment', 'Social', 'distancing', 'and', 'lockdowns', 'have', 'also', 'prompted', 'altruistic', 'behaviors', 'in', 'part', 'because', 'of', 'the', 'sense', 'that', '“', 'we', '’', 're', 'all', 'in', 'this', 'together', '”', 'Many', 'people', 'report', 'being', 'bored', 'or', 'concerned', 'about', 'putting', 'on', 'weight', ';', 'others', 'have', 'discovered', 'a', 'slower', 'pace', 'of', 'life', 'and', 'by', 'not', 'going', 'out', 'and', 'socializing', 'have', 'found', 'more', 'time', 'for', 'family', 'others', 'and', 'even', 'their', 'pets', 'The', 'downside', 'of', 'self-isolation', 'or', 'social', 'lockdown', 'are', 'symptoms', 'of', 'traumatic', 'stress', 'confusion', 'and', 'anger', 'all', 'of', 'which', 'are', 'exacerbated', 'by', 'fear', 'of', 'infection', 'having', 'limited', 'access', 'to', 'supplies', 'of', 'necessities', 'inadequate', 'information', 'or', 'the', 'experience', 'of', 'economic', 'loss', 'or', 'stigma', 'This', 'stress', 'and', 'anxiety', 'can', 'lead', 'to', 'increased', 'alcohol', 'consumption', 'as', 'well', 'as', 'an', 'increase', 'in', 'domestic', 'and', 'family', 'violenceIn', 'Jingzhou', 'a', 'town', 'near', 'Wuhan', 'in', 'Hubei', 'province', 'reports', 'of', 'domestic', 'violence', 'during', 'the', 'lockdown', 'in', 'February', '2020', 'were', 'more', 'than', 'triple', 'the', 'number', 'reported', 'in', 'February', '2019', 'Essential', 'Actions', 'From', 'The', 'Business', 'Community', 'Health', 'measures', 'must', 'be', 'the', 'first', 'priority', 'for', 'governments', 'business', 'and', 'society', 'It', 'is', 'important', 'for', 'businesses', 'to', 'show', 'solidarity', 'and', 'work', 'together', 'to', 'protect', 'staff', 'local', 'communities', 'and', 'customers', 'as', 'well', 'as', 'keeping', 'supply', 'chains', 'manufacturing', 'and', 'logistics', 'workingAccording', 'to', 'research', '“', 'my', 'employer', '”', 'is', 'more', 'trusted', 'than', 'the', 'government', 'or', 'media', 'Daily', 'updates', 'on', 'a', 'company', 'website', 'with', 'input', 'from', 'scientists', 'and', 'experts', 'are', 'recommended', 'to', 'counter', 'politicized', 'messages', 'in', 'the', 'media', 'and', 'from', 'governments', 'This', 'is', 'particularly', 'true', 'for', 'large', 'companies', 'that', 'have', 'the', 'capacity', 'to', 'do', 'this', 'Messages', 'about', 'what', 'businesses', 'are', 'doing', 'for', 'their', 'employees', 'and', 'in', 'their', 'communities', 'is', 'also', 'important', 'Some', 'companies', 'are', 'helping', 'schoolchildren', 'from', 'vulnerable', 'families', 'who', 'can', 'no', 'longer', 'get', 'a', 'school', 'meal', ';', 'others', 'are', 'providing', 'public', 'health', 'messages', 'about', 'effective', 'handwashing', 'Even', 'CEOs', 'can', 'show', 'they', 'are', 'working', 'from', 'home', 'and', 'self-isolating', 'while', 'still', 'being', 'effective', 'in', 'their', 'leadership', 'Following', 'WHO', 'advice', 'there', 'is', 'a', 'need', 'for', 'the', 'business', 'community', 'to', 'move', 'from', 'general', 'support', 'to', 'specific', 'actions', 'and', 'focus', 'on', 'countries', '’', 'access', 'to', 'critical', 'supplies', 'including', 'a', '“', 'Community', 'Package', 'of', 'Critical', 'Items', '”', 'a', 'list', 'of', '46', 'items', 'that', 'all', 'countries', 'need', 'Of', 'these', 'items', '20', 'are', 'either', 'not', 'available', 'locally', 'or', 'available', 'stocks', 'are', 'too', 'limited', 'These', 'missing', 'items', 'fall', 'into', 'four', 'categories', 'Hygiene', 'Chlorine', 'HTH', '70', '%', 'alcohol', 'based', 'hand', 'rub', 'liquid', 'soap', ';', 'Diagnostics', 'lab', 'screening', 'tests', 'lab', 'confirmation', 'tests', 'enzymes', 'RNA', 'extraction', 'kits', ';', 'PPE', 'gowns', 'scrubs', 'aprons', 'sterile', 'gloves', 'protective', 'goggles', 'face', 'shields', 'masks', 'N95', 'or', 'FFP2', ';', 'Case', 'management', 'equipment', 'oxygen', 'concentrators', 'oxygen', 'delivery', 'systems', 'mechanical', 'ventilators', 'The', 'call', 'for', 'action', 'is', 'for', 'more', 'money', 'to', 'work', 'with', 'manufacturers', 'to', 'create', 'capacity', 'and', 'to', 'organize', 'purchasing', 'so', 'there', 'is', 'guaranteed', 'access', 'especially', 'for', 'poorer', 'countries', 'with', 'less', 'resilient', 'public', 'health', 'systems', 'The', 'concept', 'is', 'to', 'create', 'a', 'global', 'security', 'stockpile', 'of', 'supplies', 'and', 'equipment', 'an', 'effort', 'that', 'needs', 'Emergency', 'financingAccess', 'to', 'and', 'increases', 'in', 'manufacturing', 'capacityAccess', 'to', 'national', 'and', 'supplier', 'stockpilesWarehouses', 'and', 'distribution', 'capacity', 'Blackcoffer', 'Insights', '17-Jatin', 'TiwariGurukul', 'Kangri', 'Deemed', 'University', 'Haridwar']\n"
     ]
    }
   ],
   "source": [
    "print(tokenize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2323dfcb",
   "metadata": {},
   "source": [
    "# CALCULATE SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "653f4ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postive score= 38\n"
     ]
    }
   ],
   "source": [
    "# 1) POSITIVE SCORE\n",
    "positive_score=0\n",
    "for i in tokenize_text:\n",
    "  if(i.lower() in post):\n",
    "    positive_score+=1\n",
    "print('postive score=', positive_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b05f487b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative score= 58\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#2) NEGATIVE SCORE\n",
    "negative_score=0\n",
    "for i in tokenize_text:\n",
    "  if(i.lower() in neg):\n",
    "    negative_score+=1\n",
    "print('negative score=', negative_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "76114ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polarity_score= -0.20833333116319447\n"
     ]
    }
   ],
   "source": [
    "#3) POLARITY SCORE\n",
    "#Polarity Score = (Positive Score – Negative Score)/ ((Positive Score + Negative Score) + 0.000001)\n",
    "Polarity_Score=(positive_score-negative_score)/((positive_score+negative_score)+0.000001)\n",
    "print('polarity_score=', Polarity_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0df194f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjectivity_score -0.01857010211831931\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#4) SUBJECTIVITY SCORE\n",
    "#Subjectivity Score = (Positive Score + Negative Score)/ ((Total Words after cleaning) + 0.000001)\n",
    "subjectiivity_score=(positive_score-negative_score)/((len(tokenize_text))+ 0.000001)\n",
    "print('subjectivity_score',subjectiivity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "70f8dadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg sentence length= 199.78787878787878\n",
      "percentag of complex words=  0.28040854224698236\n",
      "fog index=  80.02731493205032\n",
      "avg no of words per sentence=  31.545454545454547\n",
      "complex words count= 302\n",
      "word count=  1077\n",
      "syllable_per_word=  2106\n",
      "personal pronouns=  3\n",
      "avg word=  5.185701021355618\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#5) AVG SENTENCE LENGTH\n",
    "length=c.shape[0]\n",
    "avg_length=[]\n",
    "for i in range(0,length):\n",
    "  avg_length.append(len(c['abc'].iloc[i]))\n",
    "avg_senetence_length=sum(avg_length)/len(avg_length)\n",
    "print('avg sentence length=', avg_senetence_length)\n",
    "     \n",
    "#6) PERCENTAGE OF COMPLEX WORDS\n",
    "vowels=['a','e','i','o','u']\n",
    "import re\n",
    "count=0\n",
    "complex_Word_Count=0\n",
    "for i in tokenize_text:\n",
    "  x=re.compile('[es|ed]$')\n",
    "  if x.match(i.lower()):\n",
    "   count+=0\n",
    "  else:\n",
    "    for j in i:\n",
    "      if(j.lower() in vowels ):\n",
    "        count+=1\n",
    "  if(count>2):\n",
    "   complex_Word_Count+=1\n",
    "  count=0\n",
    "\n",
    "Percentage_of_Complex_words=complex_Word_Count/len(tokenize_text)\n",
    "print('percentag of complex words= ',Percentage_of_Complex_words)\n",
    "\n",
    "#7) FOG INDEX\n",
    "Fog_Index = 0.4 * (avg_senetence_length + Percentage_of_Complex_words)\n",
    "print('fog index= ',Fog_Index )\n",
    "\n",
    "#8) AVG NUMBER OF WORDS PER SENTENCE\n",
    "length=c.shape[0]\n",
    "avg_length=[]\n",
    "for i in range(0,length):\n",
    "  a=[word.split( ) for word in c.iloc[i]]\n",
    "  avg_length.append(len(a[0]))\n",
    "  a=0\n",
    "#avg\n",
    "avg_no_of_words_per_sentence=sum(avg_length)/length\n",
    "print(\"avg no of words per sentence= \",avg_no_of_words_per_sentence)\n",
    "     \n",
    "#9) COMPLEX WORD COUNT\n",
    "vowels=['a','e','i','o','u']\n",
    "import re\n",
    "count=0\n",
    "complex_Word_Count=0\n",
    "for i in tokenize_text:\n",
    "  x=re.compile('[es|ed]$')\n",
    "  if x.match(i.lower()):\n",
    "   count+=0\n",
    "  else:\n",
    "    for j in i:\n",
    "      if(j.lower() in vowels ):\n",
    "        count+=1\n",
    "  if(count>2):\n",
    "   complex_Word_Count+=1\n",
    "  count=0\n",
    "print('complex words count=',  complex_Word_Count)\n",
    "\n",
    "#10) WORD COUNT\n",
    "word_count=len(tokenize_text)\n",
    "print('word count= ', word_count)\n",
    "     \n",
    "#11) SYLLABLE PER WORD\n",
    "vowels=['a','e','i','o','u']\n",
    "import re\n",
    "count=0\n",
    "for i in tokenize_text:\n",
    "  x=re.compile('[es|ed]$')\n",
    "  if x.match(i.lower()):\n",
    "   count+=0\n",
    "  else:\n",
    "    for j in i:\n",
    "      if(j.lower() in vowels ):\n",
    "        count+=1\n",
    "syllable_count=count\n",
    "print('syllable_per_word= ',syllable_count)\n",
    "     \n",
    "\n",
    "#12) PERSONAL PRONOUNS\n",
    "pronouns=['i','we','my','ours','us' ]\n",
    "import re\n",
    "count=0\n",
    "for i in tokenize_text:\n",
    "  if i.lower() in pronouns:\n",
    "   count+=1\n",
    "personal_pronouns=count\n",
    "print('personal pronouns= ',personal_pronouns )\n",
    "\n",
    "#13) AVG WORD LENGTH\n",
    "count=0\n",
    "for i in tokenize_text:\n",
    "  for j in i:\n",
    "    count+=1\n",
    "avg_word_length=count/len(tokenize_text)\n",
    "print('avg word= ', avg_word_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43449a17",
   "metadata": {},
   "source": [
    "## And here we got all scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "03d95a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data={'positive_score':positive_score,'negative_score':negative_score,'Polarity_Score':Polarity_Score,'subjectiivity_score':subjectiivity_score,'avg_senetence_length':avg_senetence_length,'Percentage_of_Complex_words':Percentage_of_Complex_words,'Fog_Index':Fog_Index,'avg_no_of_words_per_sentence':avg_no_of_words_per_sentence,'complex_Word_Count':complex_Word_Count,'word_count':word_count,'syllable_count':syllable_count,'personal_pronouns':personal_pronouns,'avg_word_length':avg_word_length}\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "685fc495",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aakash\\AppData\\Local\\Temp\\ipykernel_4264\\3814463793.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output=output.append(data,ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>Polarity_Score</th>\n",
       "      <th>subjectiivity_score</th>\n",
       "      <th>avg_senetence_length</th>\n",
       "      <th>Percentage_of_Complex_words</th>\n",
       "      <th>Fog_Index</th>\n",
       "      <th>avg_no_of_words_per_sentence</th>\n",
       "      <th>complex_Word_Count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>syllable_count</th>\n",
       "      <th>personal_pronouns</th>\n",
       "      <th>avg_word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>-0.208333</td>\n",
       "      <td>-0.01857</td>\n",
       "      <td>199.787879</td>\n",
       "      <td>0.280409</td>\n",
       "      <td>80.027315</td>\n",
       "      <td>31.545455</td>\n",
       "      <td>302.0</td>\n",
       "      <td>1077.0</td>\n",
       "      <td>2106.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.185701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   positive_score  negative_score  Polarity_Score  subjectiivity_score  \\\n",
       "0            38.0            58.0       -0.208333             -0.01857   \n",
       "\n",
       "   avg_senetence_length  Percentage_of_Complex_words  Fog_Index  \\\n",
       "0            199.787879                     0.280409  80.027315   \n",
       "\n",
       "   avg_no_of_words_per_sentence  complex_Word_Count  word_count  \\\n",
       "0                     31.545455               302.0      1077.0   \n",
       "\n",
       "   syllable_count  personal_pronouns  avg_word_length  \n",
       "0          2106.0                3.0         5.185701  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "output=pd.DataFrame()\n",
    "output=output.append(data,ignore_index=True)\n",
    "output.columns=['positive_score','negative_score','Polarity_Score','subjectiivity_score','avg_senetence_length','Percentage_of_Complex_words','Fog_Index','avg_no_of_words_per_sentence','complex_Word_Count','word_count','syllable_count','personal_pronouns','avg_word_length']\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2363c2e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[143], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f: \n\u001b[0;32m      2\u001b[0m    output\u001b[38;5;241m.\u001b[39mto_csv(f, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 3\u001b[0m files\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'files' is not defined"
     ]
    }
   ],
   "source": [
    "# with open('output.csv', 'a') as f: \n",
    "#    output.to_csv(f, index=False, header=False)\n",
    "# files.download('output.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7469db1",
   "metadata": {},
   "source": [
    "# I HAVE DONE THIS ONLY FOR ONE TEXT FILE YOU CAN DO FOR OTHER 99\\"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
